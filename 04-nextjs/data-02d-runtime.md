# Next.js Runtime Environments

> Edge Runtime vs Node.js Runtime - when to use each and performance trade-offs.

---

## Question 1: Edge Runtime vs Node.js Runtime

**Difficulty:** ğŸŸ¡ Medium
**Frequency:** â­â­â­â­
**Time:** 10 minutes
**Companies:** Vercel, Modern cloud-first teams

### Question
What are the differences between Edge Runtime and Node.js Runtime in Next.js? When should you use each?

### Answer

**Runtime Environments:**
1. **Node.js Runtime** - Full Node.js environment with complete API access
2. **Edge Runtime** - Lightweight runtime optimized for edge networks
3. **Key difference** - Trade capabilities for speed and global distribution
4. **Use case matters** - Choose based on requirements, not preference
5. **Can mix** - Different routes can use different runtimes

**Key Points:**
1. **Performance** - Edge faster globally (lower latency), Node.js faster for complex operations
2. **Capabilities** - Node.js full API, Edge restricted subset
3. **Cost** - Edge cheaper at scale (distributed), Node.js centralized
4. **Cold starts** - Edge minimal (<50ms), Node.js significant (300ms-1s)
5. **Global distribution** - Edge automatic, Node.js manual replication

### Code Example

```typescript
// 1. EDGE RUNTIME CONFIGURATION
// app/api/edge-handler/route.ts
export const runtime = 'edge'; // Run on edge network

export async function GET(request: Request) {
  // Edge Runtime - Restricted API
  const userAgent = request.headers.get('user-agent');
  const geo = request.headers.get('x-vercel-ip-country');

  // âœ… ALLOWED: Fetch, Response, Headers, URL
  const data = await fetch('https://api.example.com/data');

  // âŒ NOT ALLOWED: fs, path, crypto (Node.js APIs)
  // const fs = require('fs'); // ERROR

  return Response.json({
    location: geo,
    userAgent,
    data: await data.json()
  });
}

// 2. NODE.JS RUNTIME CONFIGURATION
// app/api/node-handler/route.ts
export const runtime = 'nodejs'; // Run on Node.js (default)

export async function GET() {
  // Full Node.js API available
  const fs = require('fs');
  const path = require('path');
  const crypto = require('crypto');

  // âœ… Complex operations allowed
  const data = fs.readFileSync(path.join(process.cwd(), 'data.json'));
  const hash = crypto.createHash('sha256').update(data).digest('hex');

  // âœ… Database connections, file system, etc.
  const dbResult = await db.query('SELECT * FROM users');

  return Response.json({ hash, users: dbResult });
}

// 3. EDGE MIDDLEWARE (always runs at edge)
// middleware.ts
export function middleware(request: Request) {
  // Automatically runs at edge
  const country = request.headers.get('x-vercel-ip-country');

  // Redirect based on location
  if (country === 'DE') {
    return Response.redirect(new URL('/de', request.url));
  }

  // A/B testing at edge
  const bucket = Math.random() > 0.5 ? 'A' : 'B';
  const response = NextResponse.next();
  response.cookies.set('bucket', bucket);

  return response;
}

// 4. MIXED RUNTIME APPROACH
// app/api/hybrid/route.ts

// Edge handler for fast initial response
export const runtime = 'edge';

export async function GET(request: Request) {
  const cache = await fetch('https://cdn.example.com/cache.json');

  if (cache.ok) {
    // Return cached response from edge
    return cache;
  }

  // If cache miss, redirect to Node.js handler
  return Response.redirect(new URL('/api/node-handler', request.url));
}

// 5. EDGE LIMITATIONS EXAMPLE
// âŒ BAD: Using Node.js APIs at edge
export const runtime = 'edge';

export async function GET() {
  // ERROR: fs is not available at edge
  const fs = require('fs');
  const data = fs.readFileSync('./data.json');
  return Response.json(data);
}

// âœ… GOOD: Use fetch or environment variables
export const runtime = 'edge';

export async function GET() {
  // Fetch data from external source
  const data = await fetch('https://api.example.com/data.json');

  // Or use environment variables
  const apiKey = process.env.API_KEY; // Available at edge

  return Response.json(await data.json());
}

// 6. PERFORMANCE COMPARISON
// pages/api/slow-node.ts
export default async function handler(req, res) {
  // Runs on Node.js (single region)
  const start = Date.now();

  // Database query
  const data = await db.query('SELECT * FROM products');

  const duration = Date.now() - start;
  console.log(`Node.js: ${duration}ms`); // 150-500ms typical

  res.json(data);
}

// pages/api/fast-edge.ts
export const config = { runtime: 'edge' };

export default async function handler(req) {
  // Runs at edge (global distribution)
  const start = Date.now();

  // Fetch from cache or API
  const data = await fetch('https://api.example.com/products');

  const duration = Date.now() - start;
  console.log(`Edge: ${duration}ms`); // 10-50ms typical

  return Response.json(await data.json());
}

// 7. GEOLOCATION AT EDGE
// app/api/geo/route.ts
export const runtime = 'edge';

export async function GET(request: Request) {
  // Access geolocation headers
  const geo = {
    country: request.headers.get('x-vercel-ip-country'),
    region: request.headers.get('x-vercel-ip-country-region'),
    city: request.headers.get('x-vercel-ip-city'),
    latitude: request.headers.get('x-vercel-ip-latitude'),
    longitude: request.headers.get('x-vercel-ip-longitude')
  };

  return Response.json(geo);
}

// 8. DATABASE AT EDGE (with connection pooling)
// app/api/edge-db/route.ts
export const runtime = 'edge';

import { createClient } from '@vercel/postgres';

export async function GET() {
  // Edge-compatible database client
  const client = createClient({
    connectionString: process.env.POSTGRES_URL
  });

  await client.connect();

  const result = await client.query('SELECT * FROM users LIMIT 10');

  await client.end();

  return Response.json(result.rows);
}

// 9. CACHING AT EDGE
// app/api/cached-edge/route.ts
export const runtime = 'edge';

export async function GET(request: Request) {
  // Set aggressive cache headers
  const data = await fetch('https://api.example.com/data', {
    next: { revalidate: 3600 } // Cache for 1 hour
  });

  const response = new Response(JSON.stringify(await data.json()), {
    headers: {
      'Content-Type': 'application/json',
      'Cache-Control': 'public, s-maxage=3600, stale-while-revalidate=7200'
    }
  });

  return response;
}

// 10. DECISION MATRIX

/*
Use Edge Runtime when:
â”œâ”€ Need low latency globally
â”œâ”€ Simple data transformations
â”œâ”€ No Node.js-specific APIs needed
â”œâ”€ Geolocation/personalization based on request headers
â””â”€ High traffic (millions of requests)

Use Node.js Runtime when:
â”œâ”€ Need full Node.js APIs (fs, crypto, child_process)
â”œâ”€ Complex server-side operations
â”œâ”€ Database connections (non-edge compatible)
â”œâ”€ File uploads/processing
â””â”€ Legacy code migration

Examples:
â”œâ”€ Edge: A/B testing, redirects, geolocation, simple APIs
â””â”€ Node.js: Image processing, PDF generation, complex business logic
*/
```

---

<details>
<summary><strong>ğŸ” Deep Dive: Edge Runtime Architecture & Global Distribution</strong></summary>

### What is Edge Runtime?

**Edge Runtime** is a lightweight JavaScript runtime optimized for running at the edge of cloud networks (close to users globally). Unlike traditional Node.js servers that run in centralized data centers, Edge Runtime distributes your code across 150+ global locations.

#### Architecture Comparison

**Node.js Runtime (Traditional):**

```
User (Tokyo) â†’ 150ms network latency â†’ Server (US-East) â†’ 50ms processing â†’ 150ms return
Total: 350ms

Scaling:
â”œâ”€ Vertical: Add more CPU/RAM to server
â”œâ”€ Horizontal: Add more servers in same region
â””â”€ Multi-region: Manually deploy to different regions
```

**Edge Runtime (Distributed):**

```
User (Tokyo) â†’ 10ms network latency â†’ Edge (Tokyo) â†’ 5ms processing â†’ 10ms return
Total: 25ms (14x faster!)

Scaling:
â”œâ”€ Automatic distribution to 150+ locations
â”œâ”€ No manual replication needed
â””â”€ Cold start: <50ms (vs 300ms Node.js)
```

### Edge Runtime Internals

**V8 Isolates Architecture:**

Edge Runtime uses **V8 Isolates** instead of full Node.js processes. This is the key to its performance:

```
Node.js Process (traditional):
â”œâ”€ Full V8 engine instance
â”œâ”€ Complete Node.js API
â”œâ”€ Process overhead: ~50MB memory
â”œâ”€ Cold start: 300-1000ms
â””â”€ Concurrent limit: 100-500 processes per server

V8 Isolate (Edge Runtime):
â”œâ”€ Lightweight V8 context
â”œâ”€ Restricted API (Web Standards)
â”œâ”€ Memory overhead: ~2-5MB
â”œâ”€ Cold start: <50ms
â””â”€ Concurrent limit: Thousands per server
```

**How V8 Isolates work:**

```typescript
// Multiple requests running in parallel in same V8 engine
V8 Engine
â”œâ”€ Isolate 1 (Request from Tokyo)
â”‚  â””â”€ Running your edge function
â”œâ”€ Isolate 2 (Request from London)
â”‚  â””â”€ Running your edge function
â”œâ”€ Isolate 3 (Request from New York)
â”‚  â””â”€ Running your edge function
â””â”€ ... (thousands more)

Each isolate:
â”œâ”€ Isolated memory space
â”œâ”€ Cannot access other isolates
â”œâ”€ Shares same V8 engine (efficient)
â””â”€ Minimal startup cost
```

### Edge Runtime Limitations

**API Restrictions:**

Edge Runtime only supports **Web Standard APIs** (not full Node.js):

```typescript
// âœ… ALLOWED (Web Standards)
â”œâ”€ fetch() - HTTP requests
â”œâ”€ Response, Request - Web APIs
â”œâ”€ Headers, URL, URLSearchParams
â”œâ”€ crypto (Web Crypto API, not Node.js crypto)
â”œâ”€ TextEncoder, TextDecoder
â”œâ”€ atob, btoa
â”œâ”€ setTimeout, setInterval (limited)
â”œâ”€ console.log

// âŒ NOT ALLOWED (Node.js specific)
â”œâ”€ fs (file system)
â”œâ”€ path
â”œâ”€ os
â”œâ”€ child_process
â”œâ”€ net, http (Node.js modules)
â”œâ”€ crypto (Node.js version)
â”œâ”€ Buffer (use ArrayBuffer instead)
```

**Example: What you CAN'T do at edge:**

```typescript
// âŒ File system access
export const runtime = 'edge';

export async function GET() {
  const fs = require('fs'); // ERROR: fs not available
  const data = fs.readFileSync('./data.json');
  return Response.json(data);
}

// âŒ Node.js crypto
export const runtime = 'edge';

export async function GET() {
  const crypto = require('crypto'); // ERROR: Not the Web Crypto API
  const hash = crypto.createHash('sha256'); // Won't work
}

// âœ… Web Crypto instead
export const runtime = 'edge';

export async function GET() {
  const encoder = new TextEncoder();
  const data = encoder.encode('hello world');

  const hashBuffer = await crypto.subtle.digest('SHA-256', data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hash = hashArray.map(b => b.toString(16).padStart(2, '0')).join('');

  return Response.json({ hash });
}
```

### Global Distribution & Routing

**How requests are routed to edge:**

```
User request flow:

1. User (Tokyo) requests https://example.com/api/data
   â†“
2. DNS resolves to nearest edge location
   â†“
3. Edge (Tokyo) receives request
   â†“
4. Edge executes function in V8 Isolate
   â†“
5. Function returns response
   â†“
6. Response sent to user (10-20ms total)

If edge doesn't have function cached:
   â†“
1. Edge fetches function code from origin
   â†“
2. Caches function code locally
   â†“
3. Executes function
   â†“
4. Future requests use cached code
```

**Cold start comparison:**

```
Node.js (Serverless):
â”œâ”€ Container startup: 200-500ms
â”œâ”€ Node.js initialization: 100-300ms
â”œâ”€ Code loading: 50-200ms
â””â”€ Total cold start: 350-1000ms

Edge Runtime:
â”œâ”€ V8 Isolate creation: 1-5ms
â”œâ”€ Code loading (if not cached): 10-50ms
â”œâ”€ Execution: 1-10ms
â””â”€ Total cold start: 12-65ms (15x faster!)
```

### Performance Characteristics

**Latency breakdown by region:**

```
Node.js (single region US-East):
User Location    Network RTT    Processing    Total TTFB
Tokyo            150ms          50ms          200ms
London           80ms           50ms          130ms
SÃ£o Paulo        120ms          50ms          170ms
Sydney           180ms          50ms          230ms

Edge Runtime (global distribution):
User Location    Network RTT    Processing    Total TTFB
Tokyo            10ms           5ms           15ms
London           8ms            5ms           13ms
SÃ£o Paulo        12ms           5ms           17ms
Sydney           9ms            5ms           14ms

Improvement: 10-15x faster globally!
```

### When to Use Each Runtime

**Decision Matrix:**

```
Feature                     Node.js    Edge
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Global latency              âŒ Slow    âœ… Fast
Cold start                  âŒ Slow    âœ… Fast
Full Node.js API            âœ… Yes     âŒ No
File system access          âœ… Yes     âŒ No
Database (traditional)      âœ… Yes     âš ï¸  Limited
Complex processing          âœ… Yes     âš ï¸  Limited
Memory limits               âœ… High    âŒ Low (128MB)
Execution time limits       âœ… 60s+    âŒ 30s max
Cost at scale               âŒ High    âœ… Low
```

**Real-world scenarios:**

```
Use Edge Runtime:
â”œâ”€ A/B testing redirects
â”œâ”€ Geolocation-based routing
â”œâ”€ Authentication token validation
â”œâ”€ Simple API proxying
â”œâ”€ Header manipulation
â”œâ”€ Caching strategies
â””â”€ Rate limiting

Use Node.js Runtime:
â”œâ”€ Image processing (sharp, jimp)
â”œâ”€ PDF generation
â”œâ”€ File uploads
â”œâ”€ Complex database queries
â”œâ”€ Legacy code with Node.js dependencies
â”œâ”€ Long-running operations (>30s)
â””â”€ High memory requirements (>128MB)
```

</details>

---

<details>
<summary><strong>ğŸ› Real-World Scenario: Migrating API Routes to Edge Runtime</strong></summary>

### The Problem: High Global Latency

**Company:** E-commerce platform (global users, 50 countries)

**Initial Architecture:**

```
Node.js API routes deployed to US-East only:
â”œâ”€ US users: 50-100ms TTFB (good)
â”œâ”€ Europe users: 150-200ms TTFB (acceptable)
â”œâ”€ Asia users: 300-500ms TTFB (BAD)
â”œâ”€ Australia users: 400-600ms TTFB (TERRIBLE)
â””â”€ Bounce rate (Asia/AU): 35%
```

**Business Impact:**

```
Lost revenue (2023):
â”œâ”€ Asia market: $2.1M (slow checkout flow)
â”œâ”€ Australia: $850K (abandoned carts)
â”œâ”€ Total: $2.95M annually
â””â”€ Customer satisfaction (Asia): 2.8/5 stars
```

### The Solution: Migrate to Edge Runtime

**Phase 1: Identify Edge-Compatible Routes**

```typescript
// pages/api/products.ts (Node.js)
// Can be migrated to edge (no Node.js APIs used)
export default async function handler(req, res) {
  const products = await fetch('https://api.example.com/products')
    .then(r => r.json());

  res.json(products);
}

// pages/api/upload.ts (Node.js)
// CANNOT migrate to edge (uses fs and formidable)
import formidable from 'formidable';
import fs from 'fs';

export default async function handler(req, res) {
  const form = new formidable.IncomingForm();
  const file = await form.parse(req);

  // Save to disk
  fs.writeFileSync(`./uploads/${file.name}`, file.data);

  res.json({ success: true });
}
```

**Analysis:**

```
Total API routes: 45
â”œâ”€ Edge-compatible: 32 (71%)
â”‚  â””â”€ Simple data fetching, transformations
â””â”€ Node.js only: 13 (29%)
   â””â”€ File operations, image processing, PDF generation
```

**Phase 2: Migrate Compatible Routes**

```typescript
// OLD: pages/api/products.ts (Node.js)
export default async function handler(req, res) {
  const products = await fetch('https://api.example.com/products')
    .then(r => r.json());

  res.json(products);
}

// NEW: app/api/products/route.ts (Edge)
export const runtime = 'edge';

export async function GET(request: Request) {
  // Same logic, but runs at edge globally
  const products = await fetch('https://api.example.com/products', {
    next: { revalidate: 60 } // Cache for 1 minute
  }).then(r => r.json());

  return Response.json(products, {
    headers: {
      'Cache-Control': 'public, s-maxage=60, stale-while-revalidate=120'
    }
  });
}
```

**Phase 3: Add Geolocation Routing**

```typescript
// app/api/geo-products/route.ts
export const runtime = 'edge';

export async function GET(request: Request) {
  // Access user's country from edge headers
  const country = request.headers.get('x-vercel-ip-country') || 'US';

  // Fetch region-specific products
  const products = await fetch(
    `https://api.example.com/products?country=${country}`,
    { next: { revalidate: 300 } }
  ).then(r => r.json());

  return Response.json({
    country,
    products,
    message: `Showing products for ${country}`
  });
}
```

**Phase 4: Edge Middleware for A/B Testing**

```typescript
// middleware.ts (automatically runs at edge)
import { NextResponse } from 'next/server';

export function middleware(request: Request) {
  // Run A/B test at edge (no origin server hit)
  const bucket = Math.random() > 0.5 ? 'A' : 'B';

  const response = NextResponse.next();
  response.cookies.set('ab-test', bucket);

  // Redirect to variant
  if (bucket === 'B' && request.nextUrl.pathname === '/') {
    return NextResponse.redirect(new URL('/variant-b', request.url));
  }

  return response;
}

export const config = {
  matcher: ['/', '/products/:path*']
};
```

### Results After Migration

**Performance Metrics:**

```
TTFB by region (P95):

                Before (Node.js)    After (Edge)    Improvement
US              100ms               15ms            85% faster
Europe          180ms               12ms            93% faster
Asia            450ms               18ms            96% faster
Australia       550ms               20ms            96% faster

Global average: 320ms â†’ 16ms (95% improvement!)
```

**Business Impact:**

```
Revenue recovery (6 months post-migration):
â”œâ”€ Asia market: +$1.8M (recovered 86%)
â”œâ”€ Australia: +$720K (recovered 85%)
â”œâ”€ Total: +$2.52M (recovered 85% of lost revenue)

Customer satisfaction:
â”œâ”€ Asia: 2.8 â†’ 4.6 stars (64% increase)
â”œâ”€ Australia: 3.1 â†’ 4.7 stars (52% increase)

Bounce rate:
â”œâ”€ Asia: 35% â†’ 8% (77% reduction)
â”œâ”€ Australia: 32% â†’ 7% (78% reduction)
```

**Infrastructure Cost:**

```
Before (Node.js multi-region):
â”œâ”€ US-East: $1,200/month
â”œâ”€ EU-West: $1,200/month
â”œâ”€ AP-Southeast: $1,400/month
â”œâ”€ Auto-scaling: $800/month
â””â”€ Total: $4,600/month

After (Edge Runtime):
â”œâ”€ Edge Functions: $800/month
â”œâ”€ Bandwidth: $400/month
â”œâ”€ Origin (Node.js for uploads): $600/month
â””â”€ Total: $1,800/month

Savings: $2,800/month ($33,600/year!)
```

### Key Lessons

1. **Not everything needs Node.js** - 71% of routes were edge-compatible
2. **Global distribution matters** - Latency improved 10-15x for distant users
3. **Migration is incremental** - Start with simple routes, keep complex ones on Node.js
4. **Measure impact** - Track TTFB, conversion rates, bounce rates
5. **Geolocation is powerful** - Serve region-specific content at edge
6. **Cost scales better** - Edge cheaper at high traffic volumes

---

---

<details>
<summary><strong>âš–ï¸ Trade-offs: Edge Runtime vs Node.js Runtime</strong></summary>

### Performance vs Capabilities

```
Edge Runtime:
â”œâ”€ Pros: 10-15x faster globally, <50ms cold start, infinite scale
â”œâ”€ Cons: Limited API, 128MB memory limit, 30s execution time
â””â”€ Best for: Simple transformations, proxying, geolocation

Node.js Runtime:
â”œâ”€ Pros: Full Node.js API, high memory, long execution (60s+)
â”œâ”€ Cons: Slower globally, 300-1000ms cold start, expensive scale
â””â”€ Best for: Complex operations, file processing, legacy code
```

### Cost Analysis

```
Traffic: 10M requests/month

Edge Runtime:
â”œâ”€ Compute: $200
â”œâ”€ Bandwidth: $100
â””â”€ Total: $300/month

Node.js Runtime (multi-region):
â”œâ”€ Servers (3 regions): $3,600
â”œâ”€ Auto-scaling: $800
â”œâ”€ Bandwidth: $200
â””â”€ Total: $4,600/month

Savings: $4,300/month with edge (93% cheaper!)
```

### When Each Makes Sense

```
Edge Runtime wins:
â”œâ”€ High traffic (>1M requests/month)
â”œâ”€ Global user base
â”œâ”€ Simple operations (fetch, transform, return)
â”œâ”€ Low latency critical
â””â”€ Cost-sensitive

Node.js Runtime wins:
â”œâ”€ Complex operations (image/PDF processing)
â”œâ”€ Node.js dependencies required
â”œâ”€ File system access needed
â”œâ”€ Legacy code migration
â””â”€ Long-running tasks (>30s)
```

### Hybrid Approach (Best of Both)

```
Smart distribution:
â”œâ”€ Edge: 90% of routes (simple APIs, redirects, auth checks)
â”œâ”€ Node.js: 10% of routes (file uploads, PDF generation, complex logic)
â””â”€ Result: Fast globally + full capabilities where needed
```

</details>

---

<details>
<summary><strong>ğŸ’¬ Explain to Junior: Runtime Environments - Simple Mental Model</strong></summary>

### The Restaurant Analogy

**Node.js Runtime = Full Restaurant Kitchen**
```
Features:
â”œâ”€ Complete appliances (oven, stove, fridge, freezer)
â”œâ”€ Can cook anything (complex recipes)
â”œâ”€ Chefs have all tools needed
â”œâ”€ Located in one place (single region)

Trade-offs:
â”œâ”€ Customers far away wait longer (high latency)
â”œâ”€ Expensive to run (rent, staff, utilities)
â”œâ”€ Setup time (heat oven, prep ingredients)
â””â”€ Limited customers served (capacity constraints)
```

**Edge Runtime = Food Truck Network**
```
Features:
â”œâ”€ Simple cooking setup (microwave, grill)
â”œâ”€ Limited menu (simple recipes only)
â”œâ”€ 150+ trucks globally (near every customer)
â”œâ”€ Instant setup (always ready)

Trade-offs:
â”œâ”€ Customers nearby (low latency everywhere)
â”œâ”€ Cheap to run (small trucks, distributed)
â”œâ”€ No setup time (always hot)
â”œâ”€ Can serve millions (infinite scale)
â””â”€ But can't cook complex dishes
```

### Interview-Ready Explanation

**When interviewer asks: "Why would you use Edge Runtime over Node.js?"**

**Your answer:**

> "Great question. Let me explain with a real example:
>
> Imagine an e-commerce API with users globally. With Node.js in US-East:
> - US users: 50ms latency (good)
> - Asia users: 400ms latency (bad)
> - Result: High bounce rate in Asia
>
> With Edge Runtime:
> - All users: 10-20ms latency (excellent)
> - Code runs in 150+ locations automatically
> - Users in Tokyo hit Tokyo edge, London users hit London edge
> - Result: Fast everywhere, higher conversion
>
> But Edge has limitations:
> - No file system (can't save uploads)
> - No full Node.js APIs (no fs, crypto, child_process)
> - Memory limited (128MB)
> - Execution time limited (30s)
>
> So I'd use a hybrid approach:
> - Edge: Simple APIs (90% of routes)
> - Node.js: Complex operations (file uploads, image processing)
> - Result: Fast globally + full capabilities where needed
>
> The decision comes down to: Do I need Node.js APIs? If not, edge is almost always better."

### Common Interview Pitfalls

**âŒ Mistake 1:** "I'll use Node.js for everything because it's familiar"

**âœ… Correct:** Node.js is familiar, but edge is 10-15x faster globally. Migrate what you can, keep what you must.

**âŒ Mistake 2:** "Edge is always faster, so I'll use it everywhere"

**âœ… Correct:** Edge is faster for simple operations. Complex operations (image processing) might be slower at edge due to memory limits.

**âŒ Mistake 3:** "I can't use databases at edge"

**âœ… Correct:** You CAN use edge-compatible databases (Vercel Postgres, PlanetScale, Supabase). Traditional databases need Node.js.

**âŒ Mistake 4:** "Migrating to edge is all-or-nothing"

**âœ… Correct:** Migrate incrementally. Start with simple routes, keep complex ones on Node.js.

---

### Common Mistakes

- âŒ Using Node.js APIs at edge (will fail)
- âŒ Not considering global latency when choosing runtime
- âŒ Trying to run long tasks at edge (30s limit)
- âŒ Ignoring memory limits at edge (128MB)
- âœ… Start with edge for simple routes
- âœ… Use Node.js for complex operations
- âœ… Monitor latency and adjust
- âœ… Use hybrid approach (best of both)

### Follow-up Questions

1. What APIs are available in Edge Runtime?
2. How does cold start differ between edge and Node.js?
3. When would you choose Node.js over edge?

### Resources
- [Edge Runtime](https://nextjs.org/docs/api-reference/edge-runtime)
- [Runtime Configuration](https://nextjs.org/docs/app/building-your-application/rendering/edge-and-nodejs-runtimes)
- [Vercel Edge Functions](https://vercel.com/docs/functions/edge-functions)

</details>

</details>

---
